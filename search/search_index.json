{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to Energy Efficiency ETL Documentation This documentation provides an overview of the Energy Efficiency ETL framework, designed to facilitate the extraction, transformation, and loading of energy data from external APIs into a target database. Table of Contents Framework Overview Configuration Files Data Fetching Data Ingestion Main Logic Utility Functions","title":"Welcome to Energy Efficiency ETL Documentation"},{"location":"index.html#welcome-to-energy-efficiency-etl-documentation","text":"This documentation provides an overview of the Energy Efficiency ETL framework, designed to facilitate the extraction, transformation, and loading of energy data from external APIs into a target database.","title":"Welcome to Energy Efficiency ETL Documentation"},{"location":"index.html#table-of-contents","text":"Framework Overview Configuration Files Data Fetching Data Ingestion Main Logic Utility Functions","title":"Table of Contents"},{"location":"framework.html","text":"Framework For code visit: github . Mentors : Zidane Sunesara , Pradeep Savalsa , Suroor Aga Mentees : Tanishq Harchandani , Manali Bhave Project Flow Here is the project flow diagram that illustrates how the different components of the project interact during the ETL process: Project Architecture The project follows a modular architecture, where each component is responsible for specific tasks in the ETL (Extract, Transform, Load) process. Project Structure 1. Configs/ This directory contains JSON configuration files, which define various parameters used throughout the ETL process. my-project/docs/configs/hourly_generation_by_energy_source.md 2. Fetch/ This package contains modules responsible for data fetching from API. provider/ : __init__.py : Initializes the provider package. EIA/ : Contains classes and methods for fetching data from the Energy Information Administration (EIA). __init__.py : Initializes the EIA package. eia_data_fetcher.py : Implements the EIADataFetcher class to retrieve data from the EIA API. __init__.py : Initializes the provider package. provider_class_manager.py : This module manages the different data providers available for fetching data. It initializes the ProviderClassManager , which routes requests to the appropriate provider class based on the configuration. 3. Ingest/ This package contains modules responsible for data ingesting into target databases. target/ : Contains modules for data ingestion into target databases. __init__.py : Initializes the target module. Xata/ : Contains classes for ingesting data into the Xata database. __init__.py : Initializes the Xata module. xata_data_ingest.py : Implements the XataIngest class to insert data into the Xata database. __init__.py : Initializes the ingest package. ingest_class_manager.py : It initializes the IngestClassManager , managing the ingestion process and determining which ingester class to use based on configuration parameters. 3. Main.py This is the entry point for the ETL process. It orchestrates the entire data pipeline, executing the following steps: Load configuration parameters from a JSON file. Fetch provider parameters for data retrieval. Fetch data from the API using the specified parameters. Preprocess the fetched data (symbol and null value replacements). Ingest transformed data into a specified target database. 4. Utils.py This module contains utility classes for loading configuration parameters and rules. ConfigParamsLoader : Loads parameters from the JSON configuration file, including provider and ingestion target details. LoadRule : Loads transformation rules, such as symbol and null value replacements, from the configuration. DataPreprocessor : Preprocesses the DataFrame by replacing unwanted symbols and null values according to the loaded rules.","title":"Framework"},{"location":"framework.html#framework","text":"For code visit: github . Mentors : Zidane Sunesara , Pradeep Savalsa , Suroor Aga Mentees : Tanishq Harchandani , Manali Bhave","title":"Framework"},{"location":"framework.html#project-flow","text":"Here is the project flow diagram that illustrates how the different components of the project interact during the ETL process:","title":"Project Flow"},{"location":"framework.html#project-architecture","text":"The project follows a modular architecture, where each component is responsible for specific tasks in the ETL (Extract, Transform, Load) process.","title":"Project Architecture"},{"location":"framework.html#project-structure","text":"","title":"Project Structure"},{"location":"framework.html#1-configs","text":"This directory contains JSON configuration files, which define various parameters used throughout the ETL process. my-project/docs/configs/hourly_generation_by_energy_source.md","title":"1. Configs/"},{"location":"framework.html#2-fetch","text":"This package contains modules responsible for data fetching from API. provider/ : __init__.py : Initializes the provider package. EIA/ : Contains classes and methods for fetching data from the Energy Information Administration (EIA). __init__.py : Initializes the EIA package. eia_data_fetcher.py : Implements the EIADataFetcher class to retrieve data from the EIA API. __init__.py : Initializes the provider package. provider_class_manager.py : This module manages the different data providers available for fetching data. It initializes the ProviderClassManager , which routes requests to the appropriate provider class based on the configuration.","title":"2. Fetch/"},{"location":"framework.html#3-ingest","text":"This package contains modules responsible for data ingesting into target databases. target/ : Contains modules for data ingestion into target databases. __init__.py : Initializes the target module. Xata/ : Contains classes for ingesting data into the Xata database. __init__.py : Initializes the Xata module. xata_data_ingest.py : Implements the XataIngest class to insert data into the Xata database. __init__.py : Initializes the ingest package. ingest_class_manager.py : It initializes the IngestClassManager , managing the ingestion process and determining which ingester class to use based on configuration parameters.","title":"3. Ingest/"},{"location":"framework.html#3-mainpy","text":"This is the entry point for the ETL process. It orchestrates the entire data pipeline, executing the following steps: Load configuration parameters from a JSON file. Fetch provider parameters for data retrieval. Fetch data from the API using the specified parameters. Preprocess the fetched data (symbol and null value replacements). Ingest transformed data into a specified target database.","title":"3. Main.py"},{"location":"framework.html#4-utilspy","text":"This module contains utility classes for loading configuration parameters and rules. ConfigParamsLoader : Loads parameters from the JSON configuration file, including provider and ingestion target details. LoadRule : Loads transformation rules, such as symbol and null value replacements, from the configuration. DataPreprocessor : Preprocesses the DataFrame by replacing unwanted symbols and null values according to the loaded rules.","title":"4. Utils.py"},{"location":"main.html","text":"Main Logic Documentation Overview The main.py module orchestrates the entire data processing pipeline for the Energy Efficiency ETL project. It is responsible for loading configuration parameters, fetching data from specified providers, preprocessing the data, and ultimately ingesting it into the target database. Method: run_pipeline(config_path) This is the main function that coordinates the execution of the ETL process. Here\u2019s a detailed explanation of the steps involved in the main.py logic, along with a flow chart that illustrates the function invocation process for the Energy Efficiency ETL pipeline. Steps Involved 1. Load Configuration Parameters - The ConfigParamsLoader class is instantiated with the provided config_path . - Configuration parameters are loaded from the specified JSON file. - The provider name is extracted from the configuration for later use. config_loader = ConfigParamsLoader(config_path) provider_name = config_loader.get_provider_name() 2. Fetch Provider Parameters - The ProviderClassManager class is instantiated with the same configuration path. - This manager retrieves the appropriate provider class based on the extracted provider name. - The selected provider class is then called to fetch data from the API. provider_manager = ProviderClassManager(config_path) df = provider_manager.fetch_data(provider_name) 3. Data Preprocessing - The LoadRule class is instantiated to load any preprocessing rules defined in the configuration. - The symbols to be replaced and the values to replace nulls with are retrieved. - A DataPreprocessor instance is created, which applies the specified rules to clean the fetched DataFrame. rule = LoadRule(config_path) symbol_replacement = rule.load_symbol_replacement() null_value_replacement = rule.load_null_value_replacement() preprocessor = DataPreprocessor(symbol_replacement, null_value_replacement) df = preprocessor.replace_symbols(df) df = preprocessor.replace_null(df) 4. Ingest Process - The preprocessed DataFrame is prepared for ingestion. - The IngestClassManager is used to manage the ingestion process, determining which ingester to use based on the target specified in the configuration. - The data is ingested into the specified database. target = config_loader.get_target() ingest_manager = IngestClassManager(config_path) ingest_manager.ingest_data(df, target) 5. Completion - The pipeline completes, and a message is printed to indicate that all processes have been executed successfully. Conclusion The main.py file serves as the backbone i.e the brain of the ETL process, guiding the flow from configuration loading to data ingestion. Each step is modular, allowing for easy modifications or extensions of the pipeline in the future. The detailed workflow ensures that the data is efficiently and accurately processed from source to target.","title":"Main Logic"},{"location":"main.html#main-logic-documentation","text":"","title":"Main Logic Documentation"},{"location":"main.html#overview","text":"The main.py module orchestrates the entire data processing pipeline for the Energy Efficiency ETL project. It is responsible for loading configuration parameters, fetching data from specified providers, preprocessing the data, and ultimately ingesting it into the target database.","title":"Overview"},{"location":"main.html#method-run_pipelineconfig_path","text":"This is the main function that coordinates the execution of the ETL process. Here\u2019s a detailed explanation of the steps involved in the main.py logic, along with a flow chart that illustrates the function invocation process for the Energy Efficiency ETL pipeline.","title":"Method: run_pipeline(config_path)"},{"location":"main.html#steps-involved","text":"1. Load Configuration Parameters - The ConfigParamsLoader class is instantiated with the provided config_path . - Configuration parameters are loaded from the specified JSON file. - The provider name is extracted from the configuration for later use. config_loader = ConfigParamsLoader(config_path) provider_name = config_loader.get_provider_name() 2. Fetch Provider Parameters - The ProviderClassManager class is instantiated with the same configuration path. - This manager retrieves the appropriate provider class based on the extracted provider name. - The selected provider class is then called to fetch data from the API. provider_manager = ProviderClassManager(config_path) df = provider_manager.fetch_data(provider_name) 3. Data Preprocessing - The LoadRule class is instantiated to load any preprocessing rules defined in the configuration. - The symbols to be replaced and the values to replace nulls with are retrieved. - A DataPreprocessor instance is created, which applies the specified rules to clean the fetched DataFrame. rule = LoadRule(config_path) symbol_replacement = rule.load_symbol_replacement() null_value_replacement = rule.load_null_value_replacement() preprocessor = DataPreprocessor(symbol_replacement, null_value_replacement) df = preprocessor.replace_symbols(df) df = preprocessor.replace_null(df) 4. Ingest Process - The preprocessed DataFrame is prepared for ingestion. - The IngestClassManager is used to manage the ingestion process, determining which ingester to use based on the target specified in the configuration. - The data is ingested into the specified database. target = config_loader.get_target() ingest_manager = IngestClassManager(config_path) ingest_manager.ingest_data(df, target) 5. Completion - The pipeline completes, and a message is printed to indicate that all processes have been executed successfully.","title":"Steps Involved"},{"location":"main.html#conclusion","text":"The main.py file serves as the backbone i.e the brain of the ETL process, guiding the flow from configuration loading to data ingestion. Each step is modular, allowing for easy modifications or extensions of the pipeline in the future. The detailed workflow ensures that the data is efficiently and accurately processed from source to target.","title":"Conclusion"},{"location":"utils.html","text":"Utilities Documentation Overview The utils.py module provides a set of utility classes that play a pivotal role in the ETL (Extract, Transform, Load) pipeline. It includes functionality to load configuration parameters, apply data preprocessing rules, and facilitate the smooth ingestion of cleaned data. The module ensures that the pipeline can effectively read configuration files and process data according to defined rules, making the overall process more efficient and maintainable. Classes 1. ConfigParamsLoader The ConfigParamsLoader class is responsible for loading and managing configuration parameters from a JSON configuration file. These parameters include details about data providers, ingestion targets, and data processing rules. Initialization def __init__(self, config_path: str): Parameters : config_path ( str ): The path to the JSON configuration file. Description : Initializes the ConfigParamsLoader instance with the provided configuration file path. This allows subsequent methods to access and load the configuration parameters. Methods _load_config() def _load_config(self): Returns : dict : The contents of the JSON configuration file. Description : This internal method loads the configuration file and returns its contents as a Python dictionary. It is used by other methods to access configuration values. get_provider_name() def get_provider_name(self): Returns : str : The name of the data provider specified in the configuration. Description : Retrieves the provider name (e.g., \"EIA\" ) from the configuration. This informs the ETL pipeline about which data source to use for fetching the data. get_target() def get_target(self): Returns : str : The target for data ingestion specified in the configuration (e.g., \"Xata\" ). Description : Fetches the target database or storage solution where the processed data will be ingested. 2. LoadRule The LoadRule class is responsible for loading and managing rules related to data preprocessing. This includes symbol replacement and handling null values as defined in the configuration file. Initialization def __init__(self, config_path: str): Parameters : config_path ( str ): The path to the JSON configuration file containing the data processing rules. Description : Initializes the LoadRule instance, enabling the class to read and load preprocessing rules from the specified configuration. Methods _load_config() def _load_config(self): Returns : dict : The contents of the JSON configuration file. Description : Loads the JSON configuration file and returns it as a Python dictionary, used to access the rules for data preprocessing. load_symbol_replacement() def load_symbol_replacement(self): Returns : dict : The symbol replacement rules specified in the configuration. Description : Retrieves the symbol replacement rules defined in the configuration. This includes a list of symbols to be replaced and their corresponding replacements (e.g., replacing \"-\" with \"_\" ). load_null_value_replacement() def load_null_value_replacement(self): Returns : dict : The null value replacement rules specified in the configuration. Description : Fetches the rules for replacing null values in the data. This typically specifies what value (e.g., 0 ) should replace null or missing entries in the dataset. 3. DataPreprocessor The DataPreprocessor class is responsible for applying the preprocessing rules to the fetched data. This includes replacing specified symbols in column headers and filling null values in the dataset. Initialization def __init__(self, symbol_replacement, null_value_replacement): Parameters : symbol_replacement ( dict ): A dictionary containing the symbol replacement rules. null_value_replacement ( dict ): A dictionary containing the null value replacement rules. Description : Initializes the DataPreprocessor with the necessary symbol and null value replacement rules. This setup ensures that the data cleaning operations will be applied as required. Methods replace_symbols() def replace_symbols(self, df): Parameters : df ( pd.DataFrame ): The DataFrame whose column headers will be modified. Returns : pd.DataFrame : The DataFrame with modified column headers. Description : Iterates over the symbol replacement rules and applies them to the column headers of the provided DataFrame. This method ensures that symbols specified in the configuration (e.g., \"-\" , \"%\" , \"*\" ) are replaced with the designated replacements (e.g., \"_\" ). replace_null() def replace_null(self, df): Parameters : df ( pd.DataFrame ): The DataFrame in which null values will be replaced. Returns : pd.DataFrame : The DataFrame with null values replaced. Description : Fills null values in the DataFrame with the specified replacement value. This ensures that missing data is handled consistently before the data is ingested into the target system. Conclusion The utils.py module is a critical part of the ETL pipeline, providing utility classes that facilitate the loading of configuration parameters, managing data preprocessing rules, and applying those rules to data for ingestion. The modular design of the utilities ensures that the ETL process is highly flexible, maintainable, and scalable. By utilizing the ConfigParamsLoader , LoadRule , and DataPreprocessor classes, the pipeline can adapt to different data sources, ingestion targets, and data preprocessing rules, all while ensuring data consistency and quality before it is ingested into the target system.","title":"Utilities"},{"location":"utils.html#utilities-documentation","text":"","title":"Utilities Documentation"},{"location":"utils.html#overview","text":"The utils.py module provides a set of utility classes that play a pivotal role in the ETL (Extract, Transform, Load) pipeline. It includes functionality to load configuration parameters, apply data preprocessing rules, and facilitate the smooth ingestion of cleaned data. The module ensures that the pipeline can effectively read configuration files and process data according to defined rules, making the overall process more efficient and maintainable.","title":"Overview"},{"location":"utils.html#classes","text":"","title":"Classes"},{"location":"utils.html#1-configparamsloader","text":"The ConfigParamsLoader class is responsible for loading and managing configuration parameters from a JSON configuration file. These parameters include details about data providers, ingestion targets, and data processing rules.","title":"1. ConfigParamsLoader"},{"location":"utils.html#initialization","text":"def __init__(self, config_path: str): Parameters : config_path ( str ): The path to the JSON configuration file. Description : Initializes the ConfigParamsLoader instance with the provided configuration file path. This allows subsequent methods to access and load the configuration parameters.","title":"Initialization"},{"location":"utils.html#methods","text":"","title":"Methods"},{"location":"utils.html#_load_config","text":"def _load_config(self): Returns : dict : The contents of the JSON configuration file. Description : This internal method loads the configuration file and returns its contents as a Python dictionary. It is used by other methods to access configuration values.","title":"_load_config()"},{"location":"utils.html#get_provider_name","text":"def get_provider_name(self): Returns : str : The name of the data provider specified in the configuration. Description : Retrieves the provider name (e.g., \"EIA\" ) from the configuration. This informs the ETL pipeline about which data source to use for fetching the data.","title":"get_provider_name()"},{"location":"utils.html#get_target","text":"def get_target(self): Returns : str : The target for data ingestion specified in the configuration (e.g., \"Xata\" ). Description : Fetches the target database or storage solution where the processed data will be ingested.","title":"get_target()"},{"location":"utils.html#2-loadrule","text":"The LoadRule class is responsible for loading and managing rules related to data preprocessing. This includes symbol replacement and handling null values as defined in the configuration file.","title":"2. LoadRule"},{"location":"utils.html#initialization_1","text":"def __init__(self, config_path: str): Parameters : config_path ( str ): The path to the JSON configuration file containing the data processing rules. Description : Initializes the LoadRule instance, enabling the class to read and load preprocessing rules from the specified configuration.","title":"Initialization"},{"location":"utils.html#methods_1","text":"","title":"Methods"},{"location":"utils.html#_load_config_1","text":"def _load_config(self): Returns : dict : The contents of the JSON configuration file. Description : Loads the JSON configuration file and returns it as a Python dictionary, used to access the rules for data preprocessing.","title":"_load_config()"},{"location":"utils.html#load_symbol_replacement","text":"def load_symbol_replacement(self): Returns : dict : The symbol replacement rules specified in the configuration. Description : Retrieves the symbol replacement rules defined in the configuration. This includes a list of symbols to be replaced and their corresponding replacements (e.g., replacing \"-\" with \"_\" ).","title":"load_symbol_replacement()"},{"location":"utils.html#load_null_value_replacement","text":"def load_null_value_replacement(self): Returns : dict : The null value replacement rules specified in the configuration. Description : Fetches the rules for replacing null values in the data. This typically specifies what value (e.g., 0 ) should replace null or missing entries in the dataset.","title":"load_null_value_replacement()"},{"location":"utils.html#3-datapreprocessor","text":"The DataPreprocessor class is responsible for applying the preprocessing rules to the fetched data. This includes replacing specified symbols in column headers and filling null values in the dataset.","title":"3. DataPreprocessor"},{"location":"utils.html#initialization_2","text":"def __init__(self, symbol_replacement, null_value_replacement): Parameters : symbol_replacement ( dict ): A dictionary containing the symbol replacement rules. null_value_replacement ( dict ): A dictionary containing the null value replacement rules. Description : Initializes the DataPreprocessor with the necessary symbol and null value replacement rules. This setup ensures that the data cleaning operations will be applied as required.","title":"Initialization"},{"location":"utils.html#methods_2","text":"","title":"Methods"},{"location":"utils.html#replace_symbols","text":"def replace_symbols(self, df): Parameters : df ( pd.DataFrame ): The DataFrame whose column headers will be modified. Returns : pd.DataFrame : The DataFrame with modified column headers. Description : Iterates over the symbol replacement rules and applies them to the column headers of the provided DataFrame. This method ensures that symbols specified in the configuration (e.g., \"-\" , \"%\" , \"*\" ) are replaced with the designated replacements (e.g., \"_\" ).","title":"replace_symbols()"},{"location":"utils.html#replace_null","text":"def replace_null(self, df): Parameters : df ( pd.DataFrame ): The DataFrame in which null values will be replaced. Returns : pd.DataFrame : The DataFrame with null values replaced. Description : Fills null values in the DataFrame with the specified replacement value. This ensures that missing data is handled consistently before the data is ingested into the target system.","title":"replace_null()"},{"location":"utils.html#conclusion","text":"The utils.py module is a critical part of the ETL pipeline, providing utility classes that facilitate the loading of configuration parameters, managing data preprocessing rules, and applying those rules to data for ingestion. The modular design of the utilities ensures that the ETL process is highly flexible, maintainable, and scalable. By utilizing the ConfigParamsLoader , LoadRule , and DataPreprocessor classes, the pipeline can adapt to different data sources, ingestion targets, and data preprocessing rules, all while ensuring data consistency and quality before it is ingested into the target system.","title":"Conclusion"},{"location":"configs/electricity_sales_to_customers.html","text":"Monthly Retail Sales Data Configuration Overview This configuration file is used to fetch monthly retail sales data from the EIA API. It defines details about the data provider, API endpoint, request parameters, and data transformation rules before ingesting the data into the Xata database. Configuration Structure Providers The providers section contains all the necessary information to access the EIA API and specify the parameters for fetching retail sales data. provider : Type : string Description : Specifies the data provider. In this case, it is set to \"EIA\" , the U.S. Energy Information Administration. base_url : Type : string Description : The base URL for the EIA API endpoint where the retail sales data will be fetched from. Example : https://api.eia.gov/v2/electricity/retail-sales/data/ params : Type : object Description : Contains various parameters for the API request. Params Details frequency : Type : string Description : The frequency of the data. Here, it is set to \"monthly\" , indicating monthly retail sales data will be fetched. data : Type : array Description : Specifies the fields of data to retrieve. Example : [\"customers\", \"price\", \"revenue\", \"sales\"] , which fetches the number of customers, price, revenue, and sales data. facets : Type : object Description : Contains filtering options for the data. sectorid : Type : array Description : Specifies the sectors to filter the data by. The array includes sectors like \"ALL\" , \"COM\" (Commercial), \"RES\" (Residential), etc. Example : [\"ALL\", \"COM\", \"IND\", \"RES\", \"TRA\"] . stateid : Type : array Description : Specifies the states for which the data should be fetched. Example : [\"AK\", \"AL\", \"AR\", \"CA\", \"TX\", \"NY\", \"FL\", ...] . start : Type : string or null Description : The start date for the data fetch. Setting this to null means data will be fetched from the beginning. end : Type : string or null Description : The end date for the data fetch. Setting this to null means data will be fetched up to the current date. sort : Type : array Description : Specifies the sorting order for the fetched data. Example : json [ {\"column\": \"customers\", \"direction\": \"asc\"}, {\"column\": \"period\", \"direction\": \"asc\"}, {\"column\": \"price\", \"direction\": \"asc\"}, {\"column\": \"revenue\", \"direction\": \"asc\"}, {\"column\": \"sales\", \"direction\": \"asc\"}, {\"column\": \"sectorid\", \"direction\": \"asc\"}, {\"column\": \"stateid\", \"direction\": \"asc\"} ] This indicates sorting by customers , period , price , revenue , sales , sectorid , and stateid in ascending order. offset : Type : integer Description : The offset for pagination. It specifies the starting point for fetching records. Example : 0 means to start fetching records from the beginning. length : Type : integer Description : The maximum number of records to fetch in a single request. Example : 5000 indicates that up to 5000 records will be fetched. Ingest The ingest section defines the target for the data after it is fetched and processed. target : Type : string Description : Specifies where the data will be ingested. Example : \"Xata\" indicates that the data will be ingested into the Xata database. table_name : Type : string Description : The name of the table in the target database where the data will be stored. Example : \"electricity_sales_to_customer_raw\" specifies the table name. Rules The rules section defines any data transformations that should be applied before the data is ingested. symbol_replacement : Type : object Description : Rules for replacing specific symbols or characters in the data. replacements : Type : array Description : Specifies the symbols to replace and their replacements. Example : json [ { \"symbols\": [\"-\", \"%\", \"*\"], \"replace_with\": \"_\" } ] This indicates that all occurrences of the symbols \"-\" , \"%\" , and \"*\" will be replaced with underscores ( _ ). null_value_replacement : Type : object Description : Specifies how to handle null values in the data. replace_with : Type : integer Description : The value to replace nulls with. Example : 0 indicates that any null values will be replaced with 0 . Conclusion This configuration file provides the necessary structure for fetching, transforming, and ingesting monthly retail sales data by sector and state from the EIA API into the Xata database. The transformation rules ensure that the data is clean and consistent before ingestion.","title":"Electricity Sales"},{"location":"configs/electricity_sales_to_customers.html#monthly-retail-sales-data-configuration","text":"","title":"Monthly Retail Sales Data Configuration"},{"location":"configs/electricity_sales_to_customers.html#overview","text":"This configuration file is used to fetch monthly retail sales data from the EIA API. It defines details about the data provider, API endpoint, request parameters, and data transformation rules before ingesting the data into the Xata database.","title":"Overview"},{"location":"configs/electricity_sales_to_customers.html#configuration-structure","text":"","title":"Configuration Structure"},{"location":"configs/electricity_sales_to_customers.html#providers","text":"The providers section contains all the necessary information to access the EIA API and specify the parameters for fetching retail sales data. provider : Type : string Description : Specifies the data provider. In this case, it is set to \"EIA\" , the U.S. Energy Information Administration. base_url : Type : string Description : The base URL for the EIA API endpoint where the retail sales data will be fetched from. Example : https://api.eia.gov/v2/electricity/retail-sales/data/ params : Type : object Description : Contains various parameters for the API request.","title":"Providers"},{"location":"configs/electricity_sales_to_customers.html#params-details","text":"frequency : Type : string Description : The frequency of the data. Here, it is set to \"monthly\" , indicating monthly retail sales data will be fetched. data : Type : array Description : Specifies the fields of data to retrieve. Example : [\"customers\", \"price\", \"revenue\", \"sales\"] , which fetches the number of customers, price, revenue, and sales data. facets : Type : object Description : Contains filtering options for the data. sectorid : Type : array Description : Specifies the sectors to filter the data by. The array includes sectors like \"ALL\" , \"COM\" (Commercial), \"RES\" (Residential), etc. Example : [\"ALL\", \"COM\", \"IND\", \"RES\", \"TRA\"] . stateid : Type : array Description : Specifies the states for which the data should be fetched. Example : [\"AK\", \"AL\", \"AR\", \"CA\", \"TX\", \"NY\", \"FL\", ...] . start : Type : string or null Description : The start date for the data fetch. Setting this to null means data will be fetched from the beginning. end : Type : string or null Description : The end date for the data fetch. Setting this to null means data will be fetched up to the current date. sort : Type : array Description : Specifies the sorting order for the fetched data. Example : json [ {\"column\": \"customers\", \"direction\": \"asc\"}, {\"column\": \"period\", \"direction\": \"asc\"}, {\"column\": \"price\", \"direction\": \"asc\"}, {\"column\": \"revenue\", \"direction\": \"asc\"}, {\"column\": \"sales\", \"direction\": \"asc\"}, {\"column\": \"sectorid\", \"direction\": \"asc\"}, {\"column\": \"stateid\", \"direction\": \"asc\"} ] This indicates sorting by customers , period , price , revenue , sales , sectorid , and stateid in ascending order. offset : Type : integer Description : The offset for pagination. It specifies the starting point for fetching records. Example : 0 means to start fetching records from the beginning. length : Type : integer Description : The maximum number of records to fetch in a single request. Example : 5000 indicates that up to 5000 records will be fetched.","title":"Params Details"},{"location":"configs/electricity_sales_to_customers.html#ingest","text":"The ingest section defines the target for the data after it is fetched and processed. target : Type : string Description : Specifies where the data will be ingested. Example : \"Xata\" indicates that the data will be ingested into the Xata database. table_name : Type : string Description : The name of the table in the target database where the data will be stored. Example : \"electricity_sales_to_customer_raw\" specifies the table name.","title":"Ingest"},{"location":"configs/electricity_sales_to_customers.html#rules","text":"The rules section defines any data transformations that should be applied before the data is ingested. symbol_replacement : Type : object Description : Rules for replacing specific symbols or characters in the data. replacements : Type : array Description : Specifies the symbols to replace and their replacements. Example : json [ { \"symbols\": [\"-\", \"%\", \"*\"], \"replace_with\": \"_\" } ] This indicates that all occurrences of the symbols \"-\" , \"%\" , and \"*\" will be replaced with underscores ( _ ). null_value_replacement : Type : object Description : Specifies how to handle null values in the data. replace_with : Type : integer Description : The value to replace nulls with. Example : 0 indicates that any null values will be replaced with 0 .","title":"Rules"},{"location":"configs/electricity_sales_to_customers.html#conclusion","text":"This configuration file provides the necessary structure for fetching, transforming, and ingesting monthly retail sales data by sector and state from the EIA API into the Xata database. The transformation rules ensure that the data is clean and consistent before ingestion.","title":"Conclusion"},{"location":"configs/hourly_generation_by_energy_source.html","text":"Hourly Generation by Energy Source Configuration Overview This configuration file is used to fetch hourly generation data by energy source from the EIA API. It contains details about the data provider, API endpoint, parameters for the API request, and rules for data transformation before ingestion into the Xata database. Configuration Structure Providers The providers section contains all the necessary information to access the provider API. provider : Type : string Description : Specifies the data provider. In our case, it is set to \"EIA\". base_url : Type : string Description : The base URL for the EIA API endpoint from which the data will be fetched. Example : https://api.eia.gov/v2/electricity/rto/fuel-type-data/data/ params : Type : object Description : Contains various parameters for the API request. Params Details frequency : Type : string Description : The frequency of the data. Here, it is set to \"hourly\". data : Type : array Description : Specifies which data fields to retrieve. Example : [\"value\"] indicates that only the \"value\" field will be fetched. facets : Type : object Description : Contains filtering options for the data. fueltype : Type : array Description : Specifies the types of fuel to include in the data fetch. Example : [\"COL\", \"NG\", \"NUC\", \"OIL\", \"OTH\", \"SUN\", \"UNK\", \"WAT\", \"WND\"] . respondent : Type : array Description : Specifies the respondents from whom the data is being fetched. Example : [\"AEC\", \"AECI\", \"AVA\", \"AVRN\", \"AZPS\", ...] . start : Type : string or null Description : The start date for the data fetch. Setting this to null indicates that it will fetch all available data from the beginning. end : Type : string or null Description : The end date for the data fetch. Setting this to null indicates that it will fetch data up to the current date. sort : Type : array Description : Specifies the sorting order of the fetched data. Example : json [ {\"column\": \"fueltype\", \"direction\": \"desc\"}, {\"column\": \"respondent\", \"direction\": \"asc\"}, {\"column\": \"period\", \"direction\": \"asc\"}, {\"column\": \"value\", \"direction\": \"asc\"} ] This indicates sorting first by fueltype in descending order, followed by respondent , period , and value in ascending order. offset : Type : integer Description : The offset for pagination. It determines where to start fetching records. Example : 0 means start from the beginning. length : Type : integer Description : The maximum number of records to fetch in a single request. Example : 5000 indicates that up to 5000 records will be fetched. Ingest The ingest section defines where the fetched data will be stored. target : Type : string Description : Specifies the target database for ingestion. Example : \"Xata\" indicates that the data will be ingested into the Xata database. table_name : Type : string Description : The name of the table in the target database where the data will be stored. Example : \"test\" indicates the name of the table. Rules The rules section contains transformation rules for the data before ingestion. symbol_replacement : Type : object Description : Rules for replacing specific symbols in the data. replacements : Type : array Description : Specifies the symbols to replace and their replacements. Example : json [ { \"symbols\": [\"-\"], \"replace_with\": \"_\" } ] This indicates that all hyphens ( - ) in the data will be replaced with underscores ( _ ). null_value_replacement : Type : object Description : Specifies how to handle null values in the data. replace_with : Type : integer Description : The value to replace nulls with. Example : 0 indicates that null values will be replaced with 0 . Conclusion This configuration file is essential for retrieving, transforming, and ingesting hourly generation data by energy source from the EIA API into the Xata database. The transformation rules ensure that the data is clean and consistent before ingestion.","title":"Hourly Generation"},{"location":"configs/hourly_generation_by_energy_source.html#hourly-generation-by-energy-source-configuration","text":"","title":"Hourly Generation by Energy Source Configuration"},{"location":"configs/hourly_generation_by_energy_source.html#overview","text":"This configuration file is used to fetch hourly generation data by energy source from the EIA API. It contains details about the data provider, API endpoint, parameters for the API request, and rules for data transformation before ingestion into the Xata database.","title":"Overview"},{"location":"configs/hourly_generation_by_energy_source.html#configuration-structure","text":"","title":"Configuration Structure"},{"location":"configs/hourly_generation_by_energy_source.html#providers","text":"The providers section contains all the necessary information to access the provider API. provider : Type : string Description : Specifies the data provider. In our case, it is set to \"EIA\". base_url : Type : string Description : The base URL for the EIA API endpoint from which the data will be fetched. Example : https://api.eia.gov/v2/electricity/rto/fuel-type-data/data/ params : Type : object Description : Contains various parameters for the API request.","title":"Providers"},{"location":"configs/hourly_generation_by_energy_source.html#params-details","text":"frequency : Type : string Description : The frequency of the data. Here, it is set to \"hourly\". data : Type : array Description : Specifies which data fields to retrieve. Example : [\"value\"] indicates that only the \"value\" field will be fetched. facets : Type : object Description : Contains filtering options for the data. fueltype : Type : array Description : Specifies the types of fuel to include in the data fetch. Example : [\"COL\", \"NG\", \"NUC\", \"OIL\", \"OTH\", \"SUN\", \"UNK\", \"WAT\", \"WND\"] . respondent : Type : array Description : Specifies the respondents from whom the data is being fetched. Example : [\"AEC\", \"AECI\", \"AVA\", \"AVRN\", \"AZPS\", ...] . start : Type : string or null Description : The start date for the data fetch. Setting this to null indicates that it will fetch all available data from the beginning. end : Type : string or null Description : The end date for the data fetch. Setting this to null indicates that it will fetch data up to the current date. sort : Type : array Description : Specifies the sorting order of the fetched data. Example : json [ {\"column\": \"fueltype\", \"direction\": \"desc\"}, {\"column\": \"respondent\", \"direction\": \"asc\"}, {\"column\": \"period\", \"direction\": \"asc\"}, {\"column\": \"value\", \"direction\": \"asc\"} ] This indicates sorting first by fueltype in descending order, followed by respondent , period , and value in ascending order. offset : Type : integer Description : The offset for pagination. It determines where to start fetching records. Example : 0 means start from the beginning. length : Type : integer Description : The maximum number of records to fetch in a single request. Example : 5000 indicates that up to 5000 records will be fetched.","title":"Params Details"},{"location":"configs/hourly_generation_by_energy_source.html#ingest","text":"The ingest section defines where the fetched data will be stored. target : Type : string Description : Specifies the target database for ingestion. Example : \"Xata\" indicates that the data will be ingested into the Xata database. table_name : Type : string Description : The name of the table in the target database where the data will be stored. Example : \"test\" indicates the name of the table.","title":"Ingest"},{"location":"configs/hourly_generation_by_energy_source.html#rules","text":"The rules section contains transformation rules for the data before ingestion. symbol_replacement : Type : object Description : Rules for replacing specific symbols in the data. replacements : Type : array Description : Specifies the symbols to replace and their replacements. Example : json [ { \"symbols\": [\"-\"], \"replace_with\": \"_\" } ] This indicates that all hyphens ( - ) in the data will be replaced with underscores ( _ ). null_value_replacement : Type : object Description : Specifies how to handle null values in the data. replace_with : Type : integer Description : The value to replace nulls with. Example : 0 indicates that null values will be replaced with 0 .","title":"Rules"},{"location":"configs/hourly_generation_by_energy_source.html#conclusion","text":"This configuration file is essential for retrieving, transforming, and ingesting hourly generation data by energy source from the EIA API into the Xata database. The transformation rules ensure that the data is clean and consistent before ingestion.","title":"Conclusion"},{"location":"data-model/cardinality.html","text":"The relationships are depicted using ||--o|, which represents a \"one-to-many\" relationship, where the table on the left side (with the || symbol) is the \"one\" side, and the table on the right side (with the o| symbol) is the \"many\" side. Explanation of Relationships: state_region_mapping ||--o| electricity_sale_to_customer_raw: One region can have many entries in the raw electricity sales data table (1-to-many relationship). BA_region_mapping ||--o| hourly_generation_by_energy_source: Each Balancing Authority (BA) can have multiple records in the hourly generation data (1-to-many relationship). hourly_generation_by_energy_source ||--o| hourly_generation_by_energy_source_daily_interval: Each hourly record of energy generation can be aggregated into a daily total (1-to-many relationship). hourly_generation_by_energy_source_daily_interval ||--o| generation_consumption_by_region: Each daily generation record can be linked to regional generation and consumption metrics (1-to-many relationship). electricity_sale_to_customer_raw ||--o| electricity_sale_to_cust_month: Raw sales data is aggregated into monthly sales data (1-to-many relationship). electricity_sale_to_cust_month ||--o| generation_consumption_by_region: Monthly sales data can be joined with generation and consumption data to assess the overall performance and efficiency (1-to-many relationship). Cardinality: The || (double line) indicates a \"one\" side of the relationship. The o| (open circle) indicates a \"many\" side of the relationship. This diagram helps visualize how data from different sources (such as energy generation, sales, and consumption) is interconnected.","title":"Cardinality"},{"location":"data-model/model.html","text":"Data Models Documentation This documentation provides details about the data models used to store and analyze electricity sales, balancing authorities, state-region mappings, and hourly energy generation data. The models allow users to understand energy production, consumption, pricing, and regional efficiency on both macro and granular levels, supporting insights into electricity distribution, demand, and financial metrics. The key data models include: Balancing Authorities and Regions : The mapping between balancing authorities (BA) and geographical regions, along with state-region associations, is captured in the BA_region_mapping and state_region_mapping tables. Electricity Sales and Customer Metrics : The electricity_sale_to_cust_month table contains data on monthly electricity sales, customer counts, and financial information by region, state, and sector. Hourly Energy Generation : The hourly_generation_by_energy_source_daily_interval table provides detailed hourly generation data by energy source (e.g., wind, solar) on a daily basis, allowing for deeper analysis of generation patterns and energy source contributions. Generation and Consumption Efficiency : The generation_consumption_by_region table tracks the amount of electricity generated and consumed in each region, along with efficiency metrics that help assess how well energy generation matches consumption. Hourly Generation by Energy Source The hourly_generation_by_energy_source-raw table provides data on electricity generation for each hour, broken down by fuel type and generation entity. Column Name Units Data Type Sample Description period String String 2024-01-01T00 The timestamp of the data point (ISO 8601 format). respondent String String AECI The entity generating the electricity. respondent_name String String Associated Electric Cooperative,Inc. The full name of the respondent organization. fueltype String String WND The type of fuel used to generate electricity (abbreviation). type_name String String Wind The complete name of the fuel type. value megawatt-hours String 900 The amount of electricity generated during that hour (in MWh). Electricity Sales to Customers The electricity_sale_to_customer_raw table provides data on electricity sales to customers by state and sector for a specific period. This includes customer counts, average price, and revenue data. Column Name Units Data Type Sample Description period String String 2024-07 The month and year the data pertains to. stateid String String WV The identifier for the state reporting the data. stateDescription String String West Virginia The full name of the state. sectorid String String IND The identifier for the sector. sectorName String String industrial The name of the sector to which the data pertains. customers number of customers Integer 10944 The number of customers in that sector for that state. price cents per kilowatt-hour Float 7.73 The average price per kilowatt-hour in cents. revenue million dollars Float 96.59317 The total revenue generated in millions of dollars. sales million kilowatt hours Float 96.59317 The total electricity sales in million kilowatt-hours. BA Region Mapping Table The BA_region_mapping table maps a Balancing Authority (BA) to its corresponding geographic region. Column Name Data Type Sample Description BA_code String AECI Unique identifier for a Balancing Authority. BA_name String Associated Electric Cooperative, Inc. Full name of the Balancing Authority corresponding to the BA_code . region_code String MIDW Unique identifier for the geographic region associated with the balancing authority. region_name String Midwest Full name of the geographic region linked to the region_code . State Region Mapping Table The state_region_mapping table links U.S. states to their respective geographic regions using region codes. Column Name Data Type Sample Description Region String Northwest Geographical area within the United States. Region_ID String NW Two-letter abbreviation representing the region. State String Idaho Name of a U.S. state. State_ID String ID Two-letter abbreviation representing the state. Hourly generation by energy source daily interval Table The hourly_generation_by_energy_source_daily_interval table provides hourly generation data for various energy sources on a daily basis. Column Name Units Data Type Sample Description balancing_authority String String Associated Electric Cooperative, Inc. The full name of the respondent organization. balancing_authority_code String String AECI A unique code that identifies the balancing authority. energy_source String String Wind The type of energy being measured or reported. energy_source_code String String WND A unique code that identifies the specific energy source. region_name Megawatt-hours String Midwest The name of the geographical region where the energy is generated. region_code String String MW A unique code representing the region. measurement_date Date Date 1/1/2019 The date on which the energy measurements were taken. hour_ending_01 Megawatt-hours Integer 100 The amount of energy generated at the end of the first hour of the day. hour_ending_02 Megawatt-hours Integer 150 The amount of energy generated at the end of the second hour of the day. hour_ending_03 Megawatt-hours Integer 200 The amount of energy generated at the end of the third hour of the day. ... ... ... ... ... hour_ending_24 Megawatt-hours Integer 900 The amount of energy generated at the end of the last hour of the day. daily Megawatt-hours Float 1000 The total amount of energy generated over the entire day. Electricity Sales to customers Monthly Table The electricity_sale_to_cust_month table records monthly electricity sales, customer counts, and financial details for different sectors in various U.S. regions. Column Name Data Type Sample Description period String (monthly) 2024-07 Monthly reporting period. region String Mid-Atlantic Geographical area. region_id String MA Identifier for the region. stateid String WV Unique identifier for the state. stateDescription String West Virginia Name of the state. sectorid String IND Identifier for the sector (e.g., industrial, residential). sectorName String industrial Name of the sector. customers Integer 10944 Total number of customers served. price Float (cents per MWh) 7730 Energy price in cents per megawatt-hour (c/MWh). revenue Float (million dollars) 96.59317 Total revenue in million dollars. consumption Float (MWh) 1250022.58 Total energy consumption in megawatt-hours (MWh). Generation Consumption by Region Table The generation_consumption_by_region table tracks electricity generation, consumption, and efficiency metrics for various regions. Column Name Units Data Type Sample Description region_name String String Central Name of the geographic region. region_code String String CN Unique identifier for the region. period Timestamp Timestamp 2024-07 Time period for the data entry. generation Megawatt-hours (MWh) Float 28511431 Amount of electricity generated in megawatt-hours. consumption Megawatt-hours (MWh) Float 18877614.73 Amount of electricity consumed in megawatt-hours. efficiency Percentage Float 0.662107 Ratio of consumption to generation. Relationships Between Tables BA_region_mapping connects a Balancing Authority ( BA_code ) to a geographic region ( region_code ). state_region_mapping defines the relationship between U.S. states and geographic regions ( Region_ID ). electricity_sale_to_cust_month records energy sales data for different regions, states, and sectors, with detailed metrics such as revenue, price, and consumption. hourly_generation_by_energy_source_daily_interval provides detailed hourly generation data for various energy sources on a daily basis, with each record representing a specific day of energy generation for a particular balancing authority and energy source. generation_consumption_by_region tracks electricity generation, consumption, and efficiency at the regional level over specific periods. Usage Notes The hourly_generation_by_energy_source_daily_interval table provides high-resolution data on hourly generation, which can be used to analyze daily energy trends and patterns. The generation_consumption_by_region table is useful for understanding the overall efficiency and energy balance in each region, comparing the amount of energy generated versus the amount consumed. The efficiency field in generation_consumption_by_region is a key metric that helps analyze how much of the generated energy is being consumed in a region. Data Model Overview The following diagram illustrates the relationship between electricity generation and consumption. erDiagram BA_region_mapping { string BA_code \"Unique identifier for a Balancing Authority\" string BA_name \"Full name of the Balancing Authority\" string region_code \"Unique identifier for the geographic region\" string region_name \"Full name of the geographic region\" } state_region_mapping { string Region \"Geographical area within the United States\" string Region_ID \"Two-letter abbreviation representing the region\" string State \"Name of a U.S. state\" string State_ID \"Two-letter abbreviation representing the state\" } electricity_sale_to_customer_raw { string period \"Month and year the data pertains to\" string stateid \"Unique identifier for the state\" string stateDescription \"Full name of the state\" string sectorid \"Identifier for the sector\" string sectorName \"Name of the sector\" int customers \"Total number of customers served\" float price \"Average price per kilowatt-hour in cents\" float revenue \"Total revenue (in million dollars)\" float sales \"Total electricity sales (in million kWh)\" } hourly_generation_by_energy_source { string period \"Timestamp of the data point (ISO 8601)\" string respondent \"Entity generating the electricity\" string respondent_name \"Full name of the respondent organization\" string fueltype \"Fuel type used to generate electricity\" string type_name \"Complete name of the fuel type\" float value \"Amount of electricity generated (MWh)\" } electricity_sale_to_cust_month { string period \"Monthly reporting period\" string region \"Geographical area\" string region_id \"Identifier for the region\" string stateid \"Unique identifier for the state\" string stateDescription \"Full name of the state\" string sectorid \"Identifier for the sector\" string sectorName \"Name of the sector\" int customers \"Total number of customers served\" float price \"Energy price (c/MWh)\" float revenue \"Total revenue\" float consumption \"Total energy consumption\" } hourly_generation_by_energy_source_daily_interval { string balancing_authority \"Full name of the respondent organization\" string balancing_authority_code \"Unique code identifying the balancing authority\" string energy_source \"Type of energy being measured\" string energy_source_code \"Code identifying the energy source\" string region_name \"Name of the geographical region\" string region_code \"Unique region identifier\" date measurement_date \"Date of energy measurements\" int hour_ending_01 \"Energy generated at the end of hour 1\" int hour_ending_02 \"Energy generated at the end of hour 2\" int hour_ending_24 \"Energy generated at the end of hour 24\" float daily \"Total energy generated in the day\" } generation_consumption_by_region { string region_name \"Name of the geographic region\" string region_code \"Unique identifier for the region\" timestamp period \"Time period for the data entry\" float generation \"Electricity generation in MWh\" float consumption \"Electricity consumption in MWh\" float efficiency \"Ratio of consumption to generation\" } %% Relationships state_region_mapping ||--o| electricity_sale_to_customer_raw : \"Maps state-region to raw sales data\" BA_region_mapping ||--o| hourly_generation_by_energy_source : \"Maps BA to hourly generation\" hourly_generation_by_energy_source ||--o| hourly_generation_by_energy_source_daily_interval : \"Aggregates hourly generation data to daily\" hourly_generation_by_energy_source_daily_interval ||--o| generation_consumption_by_region : \"Joins hourly generation with consumption data\" electricity_sale_to_customer_raw ||--o| electricity_sale_to_cust_month : \"Transforms raw sales data into monthly sales data\" electricity_sale_to_cust_month ||--o| generation_consumption_by_region : \"Joins sales data with generation and consumption data\"","title":"Data Model"},{"location":"data-model/model.html#data-models-documentation","text":"This documentation provides details about the data models used to store and analyze electricity sales, balancing authorities, state-region mappings, and hourly energy generation data. The models allow users to understand energy production, consumption, pricing, and regional efficiency on both macro and granular levels, supporting insights into electricity distribution, demand, and financial metrics. The key data models include: Balancing Authorities and Regions : The mapping between balancing authorities (BA) and geographical regions, along with state-region associations, is captured in the BA_region_mapping and state_region_mapping tables. Electricity Sales and Customer Metrics : The electricity_sale_to_cust_month table contains data on monthly electricity sales, customer counts, and financial information by region, state, and sector. Hourly Energy Generation : The hourly_generation_by_energy_source_daily_interval table provides detailed hourly generation data by energy source (e.g., wind, solar) on a daily basis, allowing for deeper analysis of generation patterns and energy source contributions. Generation and Consumption Efficiency : The generation_consumption_by_region table tracks the amount of electricity generated and consumed in each region, along with efficiency metrics that help assess how well energy generation matches consumption.","title":"Data Models Documentation"},{"location":"data-model/model.html#hourly-generation-by-energy-source","text":"The hourly_generation_by_energy_source-raw table provides data on electricity generation for each hour, broken down by fuel type and generation entity. Column Name Units Data Type Sample Description period String String 2024-01-01T00 The timestamp of the data point (ISO 8601 format). respondent String String AECI The entity generating the electricity. respondent_name String String Associated Electric Cooperative,Inc. The full name of the respondent organization. fueltype String String WND The type of fuel used to generate electricity (abbreviation). type_name String String Wind The complete name of the fuel type. value megawatt-hours String 900 The amount of electricity generated during that hour (in MWh).","title":"Hourly Generation by Energy Source"},{"location":"data-model/model.html#electricity-sales-to-customers","text":"The electricity_sale_to_customer_raw table provides data on electricity sales to customers by state and sector for a specific period. This includes customer counts, average price, and revenue data. Column Name Units Data Type Sample Description period String String 2024-07 The month and year the data pertains to. stateid String String WV The identifier for the state reporting the data. stateDescription String String West Virginia The full name of the state. sectorid String String IND The identifier for the sector. sectorName String String industrial The name of the sector to which the data pertains. customers number of customers Integer 10944 The number of customers in that sector for that state. price cents per kilowatt-hour Float 7.73 The average price per kilowatt-hour in cents. revenue million dollars Float 96.59317 The total revenue generated in millions of dollars. sales million kilowatt hours Float 96.59317 The total electricity sales in million kilowatt-hours.","title":"Electricity Sales to Customers"},{"location":"data-model/model.html#ba-region-mapping-table","text":"The BA_region_mapping table maps a Balancing Authority (BA) to its corresponding geographic region. Column Name Data Type Sample Description BA_code String AECI Unique identifier for a Balancing Authority. BA_name String Associated Electric Cooperative, Inc. Full name of the Balancing Authority corresponding to the BA_code . region_code String MIDW Unique identifier for the geographic region associated with the balancing authority. region_name String Midwest Full name of the geographic region linked to the region_code .","title":"BA Region Mapping Table"},{"location":"data-model/model.html#state-region-mapping-table","text":"The state_region_mapping table links U.S. states to their respective geographic regions using region codes. Column Name Data Type Sample Description Region String Northwest Geographical area within the United States. Region_ID String NW Two-letter abbreviation representing the region. State String Idaho Name of a U.S. state. State_ID String ID Two-letter abbreviation representing the state.","title":"State Region Mapping Table"},{"location":"data-model/model.html#hourly-generation-by-energy-source-daily-interval-table","text":"The hourly_generation_by_energy_source_daily_interval table provides hourly generation data for various energy sources on a daily basis. Column Name Units Data Type Sample Description balancing_authority String String Associated Electric Cooperative, Inc. The full name of the respondent organization. balancing_authority_code String String AECI A unique code that identifies the balancing authority. energy_source String String Wind The type of energy being measured or reported. energy_source_code String String WND A unique code that identifies the specific energy source. region_name Megawatt-hours String Midwest The name of the geographical region where the energy is generated. region_code String String MW A unique code representing the region. measurement_date Date Date 1/1/2019 The date on which the energy measurements were taken. hour_ending_01 Megawatt-hours Integer 100 The amount of energy generated at the end of the first hour of the day. hour_ending_02 Megawatt-hours Integer 150 The amount of energy generated at the end of the second hour of the day. hour_ending_03 Megawatt-hours Integer 200 The amount of energy generated at the end of the third hour of the day. ... ... ... ... ... hour_ending_24 Megawatt-hours Integer 900 The amount of energy generated at the end of the last hour of the day. daily Megawatt-hours Float 1000 The total amount of energy generated over the entire day.","title":"Hourly generation by energy source daily interval Table"},{"location":"data-model/model.html#electricity-sales-to-customers-monthly-table","text":"The electricity_sale_to_cust_month table records monthly electricity sales, customer counts, and financial details for different sectors in various U.S. regions. Column Name Data Type Sample Description period String (monthly) 2024-07 Monthly reporting period. region String Mid-Atlantic Geographical area. region_id String MA Identifier for the region. stateid String WV Unique identifier for the state. stateDescription String West Virginia Name of the state. sectorid String IND Identifier for the sector (e.g., industrial, residential). sectorName String industrial Name of the sector. customers Integer 10944 Total number of customers served. price Float (cents per MWh) 7730 Energy price in cents per megawatt-hour (c/MWh). revenue Float (million dollars) 96.59317 Total revenue in million dollars. consumption Float (MWh) 1250022.58 Total energy consumption in megawatt-hours (MWh).","title":"Electricity Sales to customers Monthly Table"},{"location":"data-model/model.html#generation-consumption-by-region-table","text":"The generation_consumption_by_region table tracks electricity generation, consumption, and efficiency metrics for various regions. Column Name Units Data Type Sample Description region_name String String Central Name of the geographic region. region_code String String CN Unique identifier for the region. period Timestamp Timestamp 2024-07 Time period for the data entry. generation Megawatt-hours (MWh) Float 28511431 Amount of electricity generated in megawatt-hours. consumption Megawatt-hours (MWh) Float 18877614.73 Amount of electricity consumed in megawatt-hours. efficiency Percentage Float 0.662107 Ratio of consumption to generation.","title":"Generation Consumption by Region Table"},{"location":"data-model/model.html#relationships-between-tables","text":"BA_region_mapping connects a Balancing Authority ( BA_code ) to a geographic region ( region_code ). state_region_mapping defines the relationship between U.S. states and geographic regions ( Region_ID ). electricity_sale_to_cust_month records energy sales data for different regions, states, and sectors, with detailed metrics such as revenue, price, and consumption. hourly_generation_by_energy_source_daily_interval provides detailed hourly generation data for various energy sources on a daily basis, with each record representing a specific day of energy generation for a particular balancing authority and energy source. generation_consumption_by_region tracks electricity generation, consumption, and efficiency at the regional level over specific periods.","title":"Relationships Between Tables"},{"location":"data-model/model.html#usage-notes","text":"The hourly_generation_by_energy_source_daily_interval table provides high-resolution data on hourly generation, which can be used to analyze daily energy trends and patterns. The generation_consumption_by_region table is useful for understanding the overall efficiency and energy balance in each region, comparing the amount of energy generated versus the amount consumed. The efficiency field in generation_consumption_by_region is a key metric that helps analyze how much of the generated energy is being consumed in a region.","title":"Usage Notes"},{"location":"data-model/model.html#data-model-overview","text":"The following diagram illustrates the relationship between electricity generation and consumption. erDiagram BA_region_mapping { string BA_code \"Unique identifier for a Balancing Authority\" string BA_name \"Full name of the Balancing Authority\" string region_code \"Unique identifier for the geographic region\" string region_name \"Full name of the geographic region\" } state_region_mapping { string Region \"Geographical area within the United States\" string Region_ID \"Two-letter abbreviation representing the region\" string State \"Name of a U.S. state\" string State_ID \"Two-letter abbreviation representing the state\" } electricity_sale_to_customer_raw { string period \"Month and year the data pertains to\" string stateid \"Unique identifier for the state\" string stateDescription \"Full name of the state\" string sectorid \"Identifier for the sector\" string sectorName \"Name of the sector\" int customers \"Total number of customers served\" float price \"Average price per kilowatt-hour in cents\" float revenue \"Total revenue (in million dollars)\" float sales \"Total electricity sales (in million kWh)\" } hourly_generation_by_energy_source { string period \"Timestamp of the data point (ISO 8601)\" string respondent \"Entity generating the electricity\" string respondent_name \"Full name of the respondent organization\" string fueltype \"Fuel type used to generate electricity\" string type_name \"Complete name of the fuel type\" float value \"Amount of electricity generated (MWh)\" } electricity_sale_to_cust_month { string period \"Monthly reporting period\" string region \"Geographical area\" string region_id \"Identifier for the region\" string stateid \"Unique identifier for the state\" string stateDescription \"Full name of the state\" string sectorid \"Identifier for the sector\" string sectorName \"Name of the sector\" int customers \"Total number of customers served\" float price \"Energy price (c/MWh)\" float revenue \"Total revenue\" float consumption \"Total energy consumption\" } hourly_generation_by_energy_source_daily_interval { string balancing_authority \"Full name of the respondent organization\" string balancing_authority_code \"Unique code identifying the balancing authority\" string energy_source \"Type of energy being measured\" string energy_source_code \"Code identifying the energy source\" string region_name \"Name of the geographical region\" string region_code \"Unique region identifier\" date measurement_date \"Date of energy measurements\" int hour_ending_01 \"Energy generated at the end of hour 1\" int hour_ending_02 \"Energy generated at the end of hour 2\" int hour_ending_24 \"Energy generated at the end of hour 24\" float daily \"Total energy generated in the day\" } generation_consumption_by_region { string region_name \"Name of the geographic region\" string region_code \"Unique identifier for the region\" timestamp period \"Time period for the data entry\" float generation \"Electricity generation in MWh\" float consumption \"Electricity consumption in MWh\" float efficiency \"Ratio of consumption to generation\" } %% Relationships state_region_mapping ||--o| electricity_sale_to_customer_raw : \"Maps state-region to raw sales data\" BA_region_mapping ||--o| hourly_generation_by_energy_source : \"Maps BA to hourly generation\" hourly_generation_by_energy_source ||--o| hourly_generation_by_energy_source_daily_interval : \"Aggregates hourly generation data to daily\" hourly_generation_by_energy_source_daily_interval ||--o| generation_consumption_by_region : \"Joins hourly generation with consumption data\" electricity_sale_to_customer_raw ||--o| electricity_sale_to_cust_month : \"Transforms raw sales data into monthly sales data\" electricity_sale_to_cust_month ||--o| generation_consumption_by_region : \"Joins sales data with generation and consumption data\"","title":"Data Model Overview"},{"location":"fetch/provider/EIA.html","text":"EIA Data Fetcher and Provider Class Manager Documentation Overview This documentation provides an overview of the ProviderClassManager and EIADataFetcher classes, which are responsible for fetching energy data from the EIA API. The ProviderClassManager manages different data provider classes and orchestrates the data retrieval process.. Classes 1. ProviderClassManager The ProviderClassManager is responsible for managing the data fetching process from various providers. Initialization def __init__(self, config_path: str): Initializes the ProviderClassManager with a specified configuration path and a mapping of available data provider classes. Mapping self.providers = {'EIA': EIADataFetcher}: Maps the provider name to the corresponding data fetching class. Method: fetch_data() def fetch_data(self, provider_name: str): This method fetches data using the specified provider. Arguments: provider_name: The name of the provider to fetch data from (e.g., \"EIA\"). Description: Looks up the appropriate provider class based on the provided provider name. If the provider is not found, it logs an error and raises a ValueError. Creates an instance of the selected provider class, passing the configuration path. Calls the fetch_data method of the provider instance to perform the actual data fetching. 2. EIADataFetcher The EIADataFetcher class handles the interaction with the EIA API, managing API requests and data retrieval. Initialization def __init__(self, config_path: str): Initializes the EIADataFetcher with a specified configuration path. Method: fetch_data() def fetch_data(self) -> pd.DataFrame: Fetches data from the EIA API, handling pagination as necessary. Description Establishes a connection to the EIA API and constructs query parameters. Sends GET requests to the API and processes the responses. Normalizes the JSON response data into a Pandas DataFrame. Executes the insertion within a transaction to ensure data integrity. Handles pagination by iterating through the data until all available records are fetched. Raises exceptions if the response status is not successful or the data format is unexpected. Logging: Logs the number of records fetched with each API call. Logs errors that occur during the data fetching process, ensuring traceability.","title":"EIA"},{"location":"fetch/provider/EIA.html#eia-data-fetcher-and-provider-class-manager-documentation","text":"","title":"EIA Data Fetcher and Provider Class Manager Documentation"},{"location":"fetch/provider/EIA.html#overview","text":"This documentation provides an overview of the ProviderClassManager and EIADataFetcher classes, which are responsible for fetching energy data from the EIA API. The ProviderClassManager manages different data provider classes and orchestrates the data retrieval process..","title":"Overview"},{"location":"fetch/provider/EIA.html#classes","text":"","title":"Classes"},{"location":"fetch/provider/EIA.html#1-providerclassmanager","text":"The ProviderClassManager is responsible for managing the data fetching process from various providers.","title":"1. ProviderClassManager"},{"location":"fetch/provider/EIA.html#initialization","text":"def __init__(self, config_path: str): Initializes the ProviderClassManager with a specified configuration path and a mapping of available data provider classes.","title":"Initialization"},{"location":"fetch/provider/EIA.html#mapping","text":"self.providers = {'EIA': EIADataFetcher}: Maps the provider name to the corresponding data fetching class.","title":"Mapping"},{"location":"fetch/provider/EIA.html#method-fetch_data","text":"def fetch_data(self, provider_name: str): This method fetches data using the specified provider.","title":"Method: fetch_data()"},{"location":"fetch/provider/EIA.html#arguments","text":"provider_name: The name of the provider to fetch data from (e.g., \"EIA\").","title":"Arguments:"},{"location":"fetch/provider/EIA.html#description","text":"Looks up the appropriate provider class based on the provided provider name. If the provider is not found, it logs an error and raises a ValueError. Creates an instance of the selected provider class, passing the configuration path. Calls the fetch_data method of the provider instance to perform the actual data fetching.","title":"Description:"},{"location":"fetch/provider/EIA.html#2-eiadatafetcher","text":"The EIADataFetcher class handles the interaction with the EIA API, managing API requests and data retrieval.","title":"2. EIADataFetcher"},{"location":"fetch/provider/EIA.html#initialization_1","text":"def __init__(self, config_path: str): Initializes the EIADataFetcher with a specified configuration path.","title":"Initialization"},{"location":"fetch/provider/EIA.html#method-fetch_data_1","text":"def fetch_data(self) -> pd.DataFrame: Fetches data from the EIA API, handling pagination as necessary.","title":"Method: fetch_data()"},{"location":"fetch/provider/EIA.html#description_1","text":"Establishes a connection to the EIA API and constructs query parameters. Sends GET requests to the API and processes the responses. Normalizes the JSON response data into a Pandas DataFrame. Executes the insertion within a transaction to ensure data integrity. Handles pagination by iterating through the data until all available records are fetched. Raises exceptions if the response status is not successful or the data format is unexpected.","title":"Description"},{"location":"fetch/provider/EIA.html#logging","text":"Logs the number of records fetched with each API call. Logs errors that occur during the data fetching process, ensuring traceability.","title":"Logging:"},{"location":"ingest/provider/xata.html","text":"Xata Ingest and Ingest Class Manager Documentation Overview This documentation provides an overview of the XataIngest class and the IngestClassManager class, which are used for data ingestion into a XATA database using configuration files and pandas DataFrames. The IngestClassManager acts as a manager for different ingesting classes. Classes 1. IngestClassManager The IngestClassManager is responsible for managing the ingestion process. It allows for easy extension to include multiple ingesting classes. Initialization def __init__(self, config_path: str): Initializes the IngestClassManager with a specified configuration path and a mapping of available ingesting classes. Mapping self.ingesters = {'Xata': XataIngest} : Maps the target for ingestion with the corresponding ingester class. Method: ingest_data() def ingest_data(self, df: pd.DataFrame, target: str): This method ingests data using the specified target. Arguments: df : The DataFrame containing data to be ingested. target : The target for data ingestion (e.g., \"Xata\"). Description: Looks up the appropriate ingester class based on the provided target name. If the target is not found, it logs an error and raises an exception. Creates an instance of the selected ingester class, passing the configuration path and DataFrame. Calls the ingest_data method of the ingester instance to perform the actual data ingestion. 2. XataIngest The XataIngest class is designed to handle data ingestion into a XATA database. Initialization def __init__(self, config_path: str, df: pd.DataFrame): Initializes the XataIngest with a specified configuration path and DataFrame containing data to be ingested. Method: ingest_data() def ingest_data(self): Ingests data into the specified database table. Description Establishes a connection to the XATA database using the DSN. Converts the DataFrame into a list of records. Constructs an SQL INSERT statement for the target table. Executes the insertion within a transaction to ensure data integrity. Commits the transaction if successful; rolls back if an error occurs. Closes the database connection and logs the outcome. Logging: Logs the number of records inserted on success. Logs errors that occur during the insertion process.","title":"XATA"},{"location":"ingest/provider/xata.html#xata-ingest-and-ingest-class-manager-documentation","text":"","title":"Xata Ingest and Ingest Class Manager Documentation"},{"location":"ingest/provider/xata.html#overview","text":"This documentation provides an overview of the XataIngest class and the IngestClassManager class, which are used for data ingestion into a XATA database using configuration files and pandas DataFrames. The IngestClassManager acts as a manager for different ingesting classes.","title":"Overview"},{"location":"ingest/provider/xata.html#classes","text":"","title":"Classes"},{"location":"ingest/provider/xata.html#1-ingestclassmanager","text":"The IngestClassManager is responsible for managing the ingestion process. It allows for easy extension to include multiple ingesting classes.","title":"1. IngestClassManager"},{"location":"ingest/provider/xata.html#initialization","text":"def __init__(self, config_path: str): Initializes the IngestClassManager with a specified configuration path and a mapping of available ingesting classes.","title":"Initialization"},{"location":"ingest/provider/xata.html#mapping","text":"self.ingesters = {'Xata': XataIngest} : Maps the target for ingestion with the corresponding ingester class.","title":"Mapping"},{"location":"ingest/provider/xata.html#method-ingest_data","text":"def ingest_data(self, df: pd.DataFrame, target: str): This method ingests data using the specified target.","title":"Method: ingest_data()"},{"location":"ingest/provider/xata.html#arguments","text":"df : The DataFrame containing data to be ingested. target : The target for data ingestion (e.g., \"Xata\").","title":"Arguments:"},{"location":"ingest/provider/xata.html#description","text":"Looks up the appropriate ingester class based on the provided target name. If the target is not found, it logs an error and raises an exception. Creates an instance of the selected ingester class, passing the configuration path and DataFrame. Calls the ingest_data method of the ingester instance to perform the actual data ingestion.","title":"Description:"},{"location":"ingest/provider/xata.html#2-xataingest","text":"The XataIngest class is designed to handle data ingestion into a XATA database.","title":"2. XataIngest"},{"location":"ingest/provider/xata.html#initialization_1","text":"def __init__(self, config_path: str, df: pd.DataFrame): Initializes the XataIngest with a specified configuration path and DataFrame containing data to be ingested.","title":"Initialization"},{"location":"ingest/provider/xata.html#method-ingest_data_1","text":"def ingest_data(self): Ingests data into the specified database table.","title":"Method: ingest_data()"},{"location":"ingest/provider/xata.html#description_1","text":"Establishes a connection to the XATA database using the DSN. Converts the DataFrame into a list of records. Constructs an SQL INSERT statement for the target table. Executes the insertion within a transaction to ensure data integrity. Commits the transaction if successful; rolls back if an error occurs. Closes the database connection and logs the outcome.","title":"Description"},{"location":"ingest/provider/xata.html#logging","text":"Logs the number of records inserted on success. Logs errors that occur during the insertion process.","title":"Logging:"}]}